{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 608
        },
        "id": "sOhVg_viXs_W",
        "outputId": "68a19e0e-2c5c-4eca-f497-977eb0c0fe5d"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "test_database_manager (__main__.TestFunctions.test_database_manager)\n",
            "Test DatabaseManager functionality. ... ok\n",
            "test_function_selector (__main__.TestFunctions.test_function_selector)\n",
            "Test FunctionSelector functionality. ... ok\n",
            "test_test_data_mapper (__main__.TestFunctions.test_test_data_mapper)\n",
            "Test TestDataMapper functionality. ... ok\n",
            "test_mapping_criterion (__main__.TestMappingCriteria.test_mapping_criterion)\n",
            "Test that the mapping  is applied correctly. ... ok\n",
            "\n",
            "----------------------------------------------------------------------\n",
            "Ran 4 tests in 0.386s\n",
            "\n",
            "OK\n"
          ]
        },
        {
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/content/drive/MyDrive/Colab Notebooks/train.csv'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-6dba02569151>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    211\u001b[0m     \u001b[0;31m# Read dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m     \u001b[0mdb_manager\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDatabaseManager\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 213\u001b[0;31m     \u001b[0mtraining_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/MyDrive/Colab Notebooks/train.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    214\u001b[0m     \u001b[0mideal_functions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/drive/MyDrive/Colab Notebooks/ideal.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0mtest_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/drive/MyDrive/Colab Notebooks/test.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1024\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1619\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1620\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1622\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1879\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1880\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1881\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1882\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    871\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 873\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    874\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/MyDrive/Colab Notebooks/train.csv'"
          ]
        }
      ],
      "source": [
        "import unittest\n",
        "from bokeh.palettes import Category10\n",
        "from bokeh.models import ColumnDataSource\n",
        "import bokeh.plotting as bp\n",
        "from sqlalchemy import create_engine\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import bokeh.io as bio\n",
        "bio.output_notebook()\n",
        "\n",
        "\n",
        "class DatabaseManager:\n",
        "    \"\"\"Handle database.\"\"\"\n",
        "\n",
        "    def __init__(self, db_name=\"data.db\"):\n",
        "        try:\n",
        "            self.engine = create_engine(f'sqlite:///{db_name}')\n",
        "        except Exception as e:\n",
        "            print(f\"connecting to the database failed : {e}\")\n",
        "            raise\n",
        "\n",
        "    def store_dataframe(self, df, table_name):\n",
        "        \"\"\"Saves the DataFrame to a table in the database.\"\"\"\n",
        "        try:\n",
        "            df.to_sql(table_name, self.engine,\n",
        "                      if_exists='replace', index=False)\n",
        "        except Exception as e:\n",
        "            print(f\" data can not be stored : {e}\")\n",
        "            raise\n",
        "\n",
        "    def load_dataframe(self, table_name):\n",
        "        \"\"\"Loads data from a table into a DataFrame.\"\"\"\n",
        "        try:\n",
        "            return pd.read_sql(f'SELECT * FROM {table_name}', self.engine)\n",
        "        except Exception as e:\n",
        "            print(f\" data can not be loaded : {e}\")\n",
        "            raise\n",
        "\n",
        "\n",
        "class FunctionSelector:\n",
        "    \"\"\"Selects the best functions to fit the training data using the Least Squares method.\"\"\"\n",
        "\n",
        "    def __init__(self, training_data, ideal_functions):\n",
        "        self.training_data = training_data\n",
        "        self.ideal_functions = ideal_functions\n",
        "        self.max_training_deviation = {}\n",
        "\n",
        "    def select_best_functions(self):\n",
        "        \"\"\"Chooses the four functions that fit the training data the best.\"\"\"\n",
        "        best_functions = []\n",
        "        for train_col in self.training_data.columns[1:]:\n",
        "            best_func = min(\n",
        "                self.ideal_functions.columns[1:],\n",
        "                key=lambda ideal_col: np.sum(\n",
        "                    (self.training_data[train_col] - self.ideal_functions[ideal_col])**2)\n",
        "            )\n",
        "            best_functions.append(best_func)\n",
        "            self.max_training_deviation[best_func] = np.max(\n",
        "                abs(self.training_data[train_col] - self.ideal_functions[best_func]))\n",
        "        return best_functions[:4]\n",
        "\n",
        "\n",
        "class TestDataMapper:\n",
        "    \"\"\"Maps test data to the best-fitting ideal functions.\"\"\"\n",
        "\n",
        "    def __init__(self, test_data, ideal_functions, selected_functions, max_training_deviation):\n",
        "        self.test_data = test_data\n",
        "        self.ideal_functions = ideal_functions[['x'] + selected_functions]\n",
        "        self.selected_functions = selected_functions\n",
        "        self.max_training_deviation = max_training_deviation\n",
        "\n",
        "    def map_test_data(self):\n",
        "        \"\"\"Matches each test data point to the closest ideal function.\"\"\"\n",
        "        mapped_data = []\n",
        "        for _, row in self.test_data.iterrows():\n",
        "            x_val = row['x']\n",
        "            y_test = row['y']\n",
        "            min_deviation = float('inf')\n",
        "            best_function = None\n",
        "\n",
        "            for func in self.selected_functions:\n",
        "                ideal_val_arr = self.ideal_functions.loc[self.ideal_functions['x']\n",
        "                                                         == x_val, func].values\n",
        "\n",
        "                if ideal_val_arr.size > 0:\n",
        "                    y_ideal = ideal_val_arr[0]\n",
        "                    deviation = abs(y_test - y_ideal)\n",
        "                    max_train_dev = self.max_training_deviation[func]\n",
        "                    if deviation <= np.sqrt(2) * max_train_dev and deviation < min_deviation:\n",
        "                        min_deviation = deviation\n",
        "                        best_function = func\n",
        "\n",
        "            mapped_data.append([x_val, y_test, min_deviation, best_function])\n",
        "\n",
        "        return pd.DataFrame(mapped_data, columns=['x', 'y', 'delta_y', 'ideal_function'])\n",
        "\n",
        "\n",
        "class DataVisualizer:\n",
        "    \"\"\"create visualizations using Bokeh.\"\"\"\n",
        "\n",
        "    def plot_training_scatter(self, df, title, x_col='x', y_cols=None):\n",
        "        \"\"\"Plots training data as a scatter plot.\"\"\"\n",
        "        try:\n",
        "            if y_cols is None:\n",
        "                y_cols = df.columns[1:]\n",
        "\n",
        "            p = bp.figure(title=title, x_axis_label='x',\n",
        "                          y_axis_label='y', width=900, height=500)\n",
        "            colors = Category10[len(y_cols)]\n",
        "\n",
        "            for i, y_col in enumerate(y_cols):\n",
        "                p.scatter(df[x_col], df[y_col], size=1,\n",
        "                          color=colors[i], alpha=0.6, legend_label=y_col)\n",
        "\n",
        "            p.legend.title = \"Legend\"\n",
        "            p.legend.location = \"top_left\"\n",
        "            bp.show(p)\n",
        "        except Exception as e:\n",
        "            print(f\"plotting training as scatter plot failed: {e}\")\n",
        "            raise\n",
        "\n",
        "    def plot_test_scatter(self, df, title, x_col='x', y_col='y', color='blue'):\n",
        "        \"\"\"Shows test data as a scatter plot.\"\"\"\n",
        "        try:\n",
        "            p = bp.figure(title=title, x_axis_label='x',\n",
        "                          y_axis_label='y', width=900, height=500)\n",
        "            source = ColumnDataSource(df)\n",
        "            p.scatter(x_col, y_col, source=source,\n",
        "                      size=6, color=color, alpha=0.6)\n",
        "            bp.show(p)\n",
        "        except Exception as e:\n",
        "            print(f\"plotting test scatter failed : {e}\")\n",
        "            raise\n",
        "\n",
        "    def plot_ideal_functions(self, ideal_df, selected_functions, title):\n",
        "        \"\"\"Plots the selected ideal functions on a graph.\"\"\"\n",
        "        try:\n",
        "            p = bp.figure(title=title, x_axis_label='x',\n",
        "                          y_axis_label='y', width=900, height=500)\n",
        "            colors = Category10[10]\n",
        "            for i, func in enumerate(selected_functions):\n",
        "                source = ColumnDataSource(ideal_df[['x', func]])\n",
        "                p.line('x', func, source=source, line_width=2,\n",
        "                       color=colors[i % len(colors)], legend_label=func)\n",
        "            p.legend.title = \"Legend\"\n",
        "            p.legend.location = \"top_left\"\n",
        "            bp.show(p)\n",
        "        except Exception as e:\n",
        "            print(f\"plotting ideal functions failed: {e}\")\n",
        "            raise\n",
        "\n",
        "    def plot_test_data_with_ideal(self, test_df, ideal_df, selected_functions, title):\n",
        "        \"\"\"Plots test data alongside the ideal functions.\"\"\"\n",
        "        try:\n",
        "            p = bp.figure(title=title, x_axis_label='x',\n",
        "                          y_axis_label='y', width=900, height=500)\n",
        "            source = ColumnDataSource(test_df)\n",
        "            p.scatter('x', 'y', source=source, size=7, color='blue',\n",
        "                      alpha=0.6, legend_label=\"Test Data\")\n",
        "            colors = Category10[10]\n",
        "            for i, func in enumerate(selected_functions):\n",
        "                ideal_source = ColumnDataSource(ideal_df[['x', func]])\n",
        "                p.line('x', func, source=ideal_source, line_width=2,\n",
        "                       color=colors[i % len(colors)], legend_label=func)\n",
        "            p.legend.title = \"Legend\"\n",
        "            p.legend.location = \"top_left\"\n",
        "            bp.show(p)\n",
        "        except Exception as e:\n",
        "            print(f\"failed to plotting test data with ideal : {e}\")\n",
        "            raise\n",
        "\n",
        "\n",
        "# Unit Test\n",
        "class TestFunctions(unittest.TestCase):\n",
        "\n",
        "    def test_database_manager(self):\n",
        "        \"\"\"Test DatabaseManager functionality.\"\"\"\n",
        "        db_manager = DatabaseManager(db_name=\"test.db\")\n",
        "        data = pd.DataFrame({'x': [1, 2, 3], 'y': [4, 5, 6]})\n",
        "\n",
        "        # Test storing and loading data\n",
        "        db_manager.store_dataframe(data, 'test_table')\n",
        "        loaded_data = db_manager.load_dataframe('test_table')\n",
        "\n",
        "        self.assertEqual(data.shape, loaded_data.shape)\n",
        "\n",
        "    def test_function_selector(self):\n",
        "        \"\"\"Test FunctionSelector functionality.\"\"\"\n",
        "        training_data = pd.DataFrame(\n",
        "            {'x': [1, 2, 3], 'y1': [1, 2, 3], 'y2': [3, 2, 1]})\n",
        "        ideal_functions = pd.DataFrame(\n",
        "            {'x': [1, 2, 3], 'f1': [1.1, 2.1, 3.1], 'f2': [2.1, 1.1, 0.1]})\n",
        "\n",
        "        selector = FunctionSelector(training_data, ideal_functions)\n",
        "        best_functions = selector.select_best_functions()\n",
        "\n",
        "    def test_test_data_mapper(self):\n",
        "        \"\"\"Test TestDataMapper functionality.\"\"\"\n",
        "        test_data = pd.DataFrame({'x': [1, 2, 3], 'y': [1, 2, 3]})\n",
        "        ideal_functions = pd.DataFrame(\n",
        "            {'x': [1, 2, 3], 'f1': [1.1, 2.1, 3.1], 'f2': [2.1, 1.1, 0.1]})\n",
        "        selected_functions = ['f1', 'f2']\n",
        "        max_train_dev = {'f1': 0.1, 'f2': 0.2}\n",
        "\n",
        "        mapper = TestDataMapper(\n",
        "            test_data, ideal_functions, selected_functions, max_train_dev)\n",
        "        mapped_data = mapper.map_test_data()\n",
        "\n",
        "        self.assertEqual(mapped_data.shape[0], test_data.shape[0])\n",
        "\n",
        "\n",
        "class TestMappingCriteria(unittest.TestCase):\n",
        "    def setUp(self):\n",
        "        \"\"\"Set up sample data for testing.\"\"\"\n",
        "        self.test_data = pd.DataFrame({'x': [1, 2, 3], 'y': [1, 2, 3]})\n",
        "        self.ideal_functions = pd.DataFrame(\n",
        "            {'x': [1, 2, 3], 'f1': [1.1, 2.1, 3.1], 'f2': [2.1, 1.1, 0.1]})\n",
        "        self.selected_functions = ['f1', 'f2']\n",
        "        self.max_train_dev = {'f1': 0.1, 'f2': 0.2}\n",
        "\n",
        "    def test_mapping_criterion(self):\n",
        "        \"\"\"Test that the mapping  is applied correctly.\"\"\"\n",
        "        mapper = TestDataMapper(\n",
        "            self.test_data, self.ideal_functions, self.selected_functions, self.max_train_dev)\n",
        "        mapped_data = mapper.map_test_data()\n",
        "        for _, row in mapped_data.iterrows():\n",
        "            self.assertLessEqual(row['delta_y'], np.sqrt(\n",
        "                2) * self.max_train_dev.get(row['ideal_function'], float('inf')))\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Run unit tests\n",
        "    unittest.main(argv=[''], verbosity=2, exit=False)\n",
        "\n",
        "    # Read dataset\n",
        "    db_manager = DatabaseManager()\n",
        "    training_data = pd.read_csv(\n",
        "        '/content/drive/MyDrive/Colab Notebooks/train.csv')\n",
        "    ideal_functions = pd.read_csv(\n",
        "        \"/content/drive/MyDrive/Colab Notebooks/ideal.csv\")\n",
        "    test_data = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/test.csv\")\n",
        "\n",
        "    # Store data\n",
        "    for name, data in zip([\"training_data\", \"ideal_functions\", \"test_data\"], [training_data, ideal_functions, test_data]):\n",
        "        db_manager.store_dataframe(data, name)\n",
        "\n",
        "    # Select ideal functions\n",
        "    selector = FunctionSelector(training_data, ideal_functions)\n",
        "    best_functions = selector.select_best_functions()\n",
        "\n",
        "    # Map\n",
        "    mapper = TestDataMapper(test_data, ideal_functions,\n",
        "                            best_functions, selector.max_training_deviation)\n",
        "    mapped_data = mapper.map_test_data()\n",
        "    db_manager.store_dataframe(mapped_data, \"mapped_test_data\")\n",
        "\n",
        "    # Visualize\n",
        "    visualizer = DataVisualizer()\n",
        "    visualizer.plot_training_scatter(\n",
        "        training_data, \"Training Data\", y_cols=['y1', 'y2', 'y3', 'y4'])\n",
        "    visualizer.plot_test_scatter(test_data, \"Test Data\", y_col='y')\n",
        "    visualizer.plot_ideal_functions(\n",
        "        ideal_functions, best_functions, \"Ideal Functions\")\n",
        "    visualizer.plot_test_data_with_ideal(\n",
        "        test_data, ideal_functions, best_functions, \"Test Data with Ideal Functions\")\n",
        "\n",
        "    print(f\"Selected Best Functions: {best_functions}\")\n",
        "    print(\"Mapped Test Data Table:\")\n",
        "    display(mapped_data.style.set_properties(**{'text-align': 'left'}))\n",
        "\n",
        "    #    This comment is assumed as a change that has made in the code\n",
        "    # another change has been made"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
